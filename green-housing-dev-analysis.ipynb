{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Our Stakeholder, Dwell Development](images/Dwell.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Green Housing Development Analysis\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "**Authors:** Stefano Caruso, Holly Gultiano, Raul Torres\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "**Disclaimer: this notebook is for a Flatiron School data analysis project, for educational purposes only** \n",
    "\n",
    "For the past 17 years, [Dwell Development](https://www.dwelldevelopment.com/home/about/) has been building sustainable houses in the Seattle area. In this project, we use linear regression and other exploratory data analysis techniques to help them plan their next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem\n",
    "\n",
    "Seattle's population has been growing every year, largely fueled by the world-renown tech sector here, home of many top companies. \n",
    "As the population grows, the price of [rent seems to be growing with it](https://www.kiro7.com/news/local/report-seattle-rent-increased-nearly-19-year-over-year/LMUY74T3FRF5FNEWTG2KBKMJQ4/). Dwell Development wants to respond to this demand by creating new, affordable, multi-family housing for the growing population of tech workers in King County. \n",
    "\n",
    "The business problem breaks into three parts: which houses are available in the same zip codes as local tech companies, in order to minimize commute, which features correlate most with price, in order to minimize costs for both Dwell Development and the families on the housing market. With those two criteria met, we then are able to narrow down the selection of properties to find the available properties with the greatest acreage \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "Dwell Development wants to be able to make a profit from the large influx of people moving to Seattle for tech jobs. They want to be able to develop multi family properties but they do not know the best areas and which qualities correlate more to each other. There are a lot of variables but they only want to focus on the features that correlate strongest to price. We are going to fun simple and multi regression models in order to find the soltion so that Dwell Development does not waist resources in variables that are going to correlate strongly to sell price.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages used for our analysis\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from matplotlib.ticker import FormatStrFormatter, StrMethodFormatter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source Dataset\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Our housing data csv is located in the [data](./data) folder on this repository\n",
    "It is a csv file of house data from the King County area of Washington State, and it includes columns for the following features (see [this file for more in-depth descriptions](.data/column_names.md):\n",
    "> * id, a unique identifier for each house\n",
    "> * date, when the house was sold \n",
    "> * price, sale price\n",
    "> * bedrooms, number of bedrooms\n",
    "> * bathrooms, numbedr of bathrooms\n",
    "> * sqft_living, area of living space for the house\n",
    "> * sqft_lot, total area of the lot itself\n",
    "> * floors, number of storeys for the house\n",
    "> * waterfront, whether or not it is on the water\n",
    "> * view, quality of view from the house\n",
    "> * condition, condition when sold\n",
    "> * grade, quality of house as built\n",
    "> * sqft_above, total area above ground level\n",
    "> * sqft_basement, total area below ground level\n",
    "> * yr_built, the year the house was built\n",
    "> * yr_renovated, the year the house was renovated, if applicable\n",
    "> * zipcode, the zip code for the location of the house\n",
    "> * lat, latitude for the location of the house\n",
    "> * long, longitude for the location of the house \n",
    "> * sqft_living15, average area for the living spaces for the 15 neighboring houses\n",
    "> * sqft_lot15, average area for the lots for the 15 neighboring houses\n",
    "\n",
    "For our analysis, we used the \"price\" variable as the main target for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/kc_house_data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info(), data.corr() # data types and counts, and table of how correlated the features of the raw dataset are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map of Tech Companies in the King County Area\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "sourced from [this blog post](https://flatironschool.com/blog/best-tech-companies-seattle/) covering 30 companies with a lot of draw, including Google and Amazon, as well as some local start-ups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "techcompany_name = ['Microsoft', 'Google', 'Expedia', 'Getty', 'Outreach', 'Avalara', 'Amazon', 'Big Fish Games',\n",
    "                   'Tableau', 'Cray', 'Zulily', 'Redfin', 'Porch', 'SAP Concur', 'F5', 'Xealth', 'Pulumi', 'Apptentive',\n",
    "                   'Highspot', 'Impinj', 'Upbound', 'Skytap', 'Glowforge', 'Auction Edge', 'GeoEngineers', 'Twillio Zipwhip',\n",
    "                   'Whitepages', 'Amperity', 'SkyKick', 'PitchBook']\n",
    "\n",
    "techcompany_coord = {47.6395481:-122.1316979, 47.6491022:-122.3512428, 47.6278727:-122.3771439, 47.5968424:-122.3288311,\n",
    "                    47.6207149:-122.3623911, 47.5978827:-122.3309175, 47.6149968:-122.3382836, 47.6035842:-122.3375176,\n",
    "                    47.6478044:-122.3382225, 47.605816:-122.3319745, 47.6142513:-122.3522433, 47.616631:-122.332592,\n",
    "                    47.5835923:-122.3336612, 47.6161371:-122.1968104, 47.6051851:-122.331118, 47.6019789:-122.3317164,\n",
    "                    47.6107471:-122.3397581, 47.6110571:-122.3422495, 47.6114079:-122.3478381, 47.6227313:-122.33609, 47.5995348:-122.3313931,\n",
    "                    47.5980919:-122.3309701, 47.5838846:-122.3328815, 47.5990386:-122.3349373, 47.6141707:-122.3424675,\n",
    "                    47.6218759:-122.3615888, 47.614592:-122.3391944, 47.6046363:-122.3307528, 47.6210721:-122.3599327, 47.6056348:-122.3321834}\n",
    "\n",
    "tc_coord_list = list(techcompany_coord.items())\n",
    "\n",
    "def coordlister(index_num):\n",
    "    ''' quick function to get the individual coordinates of tech companies for Folium markers'''\n",
    "    return list(tc_coord_list[index_num])\n",
    "techmap = folium.Map(location=[47.605, -122.331])\n",
    "\n",
    "def maplabeler (n):\n",
    "    folium.Marker(coordlister(n)).add_to(techmap)\n",
    "\n",
    "for i in range(30):\n",
    "    maplabeler(i)\n",
    "    \n",
    "techmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "In order to produce an accurate and impactful model, we cleaned our data by removing outliers, null values, and fixing some inaccurate entries. We then dropped any features that were not relevant to our model's target prediction, and limited the locations of the houses to only those that were near the tech companies. Selection of which features to drop is shown further in the \"Data Modeling section,\" as we ran simple linear regression models to find the best fits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that are undesirable desire to our stakeholder \n",
    "clean_null = data.drop(columns=['id','date','long','yr_built','condition','view', 'waterfront', 'yr_renovated'], axis=1)\n",
    "# clean_null.describe()\n",
    "\n",
    "# locating outliers and removing them\n",
    "clean_null = clean_null.loc[clean_null['bedrooms'] < 8] \n",
    "clean_null = clean_null.loc[clean_null['bathrooms'] < 6] \n",
    "clean_null = clean_null.loc[clean_null['sqft_living'] < 6000 ]\n",
    "clean_null = clean_null.loc[clean_null['price'] < 1500000 ]\n",
    "clean_null = clean_null.loc[clean_null['bedrooms'] > .99]\n",
    "clean_null = clean_null.loc[clean_null['bathrooms'] > .99]\n",
    "clean_null = clean_null.loc[clean_null['sqft_living'] > 600 ]\n",
    "clean_null = clean_null.loc[clean_null['price'] > 100000 ] # Limiting to the price within the range of our buyer's demand\n",
    "clean_null = clean_null.loc[clean_null['sqft_lot'] < 100000 ]\n",
    "clean_null = clean_null.loc[clean_null['floors'] < 2.1 ]\n",
    "\n",
    "clean_null = clean_null.loc[clean_null['sqft_basement'] != '?' ] \n",
    "clean_null['sqft_basement'] = clean_null['sqft_basement'].astype(float)\n",
    "clean_null['true_sqft'] = clean_null['sqft_living']  - clean_null['sqft_basement']\n",
    "\n",
    "# creating a new feature of price per sqft\n",
    "clean_null['price_per_sqft'] = clean_null['price']  / clean_null['true_sqft']\n",
    "\n",
    "clean_null['grade_ordinal'] = [int(i[0:2].strip()) for i in clean_null['grade']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrowing down our dataset to include only the houses located in the zip codes from our list of tech companies above\n",
    "zip_home_size = clean_null.loc[clean_null['zipcode'].isin([98052,98102,98103,98105,98109,98119,98121,98134,98164])]\n",
    "curated_zip = np.array([98052,98102,98103,98105,98109,98119,98121,98134,98164])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the zipcodes column was of numerical type, it affected our regression line inaccurately. Here we use One Hot Encoding to change the zipcodes column into boolean type\n",
    "zips = clean_null.loc[clean_null['zipcode'].isin(curated_zip)].dropna() \n",
    "ohe = OneHotEncoder(sparse=False, drop=[98109]) # the zip code with the highest prices in Seattle. could do 98052, near the Microsoft campus as well\n",
    "ohe.fit(zips['zipcode'].to_numpy().reshape(-1, 1))\n",
    "zips_encoded = ohe.transform(zips['zipcode'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "zipcodes_ohe = pd.DataFrame(zips_encoded, columns=ohe.get_feature_names(), index=zips.index)\n",
    "\n",
    "# Dropping null values\n",
    "zip_home_size.dropna(inplace=True)\n",
    "\n",
    "zip_new_columns = zip_home_size.drop(columns=['zipcode','grade','price_per_sqft','sqft_lot15','sqft_lot','sqft_above'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features need to be scaled for the regression model to be accurate\n",
    "X = zip_new_columns.drop(['price'], axis=1)\n",
    "ss = StandardScaler().fit(X)\n",
    "znc_scaled = pd.DataFrame(ss.transform(X), columns=X.columns).dropna() # adding standard scalar to only zip_new_columns, abbreviated as znc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating two dataframes, znc_scaled and the one hot encoded zipcodes zipcodes_ohe \n",
    "zip_ohe_columns = pd.merge(znc_scaled , zipcodes_ohe, how='outer', left_index=True, right_on=znc_scaled.index) #pd.concat([znc_scaled , zipcodes_ohe], axis=1) \n",
    "zip_ohe_columns = zip_ohe_columns.drop('key_0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "To look for what features in our dataset correlate the most with house pricing in the zip codes associated with local tech companies, we ran a few simple (one variable) linear regression models using Ordinary Least Squares, in order to find the best-fit features, then we created a multiple linear regression model with house price as our target and all the best-fit feature variables (see above) as our source. We chose these features because they showed the highest correlation to house price, showing the optimal choices based on statistical measures such as R² and the Durbin-Watson test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we ran a simple linear regression on one coefficient variable to explore a possible best-fit features\n",
    "# This created a baseline model to compare our final multiple linear regression to\n",
    "y = zip_new_columns['price']\n",
    "x = zip_ohe_columns['sqft_living']\n",
    "X_c = sm.add_constant(x)\n",
    "\n",
    "\n",
    "simple_model = sm.OLS(y, X_c)\n",
    "\n",
    "\n",
    "simple_model_results = simple_model.fit()\n",
    "print(simple_model_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here we created our main model, a multiple linear regression with the target still being 'price'. \n",
    "# Our source was the best fit features found through exploratory data analysis and domain knowledge of the housing market in King County \n",
    "y = zip_new_columns['price']\n",
    "X = zip_ohe_columns # ['bedrooms', 'bathrooms', 'sqft_living', 'floors', 'sqft_basement', 'lat', 'sqft_living15', 'true_sqft', 'grade_ordinal', 'x0_98052','x0_98102', 'x0_98103', 'x0_98105', 'x0_98119']\n",
    "y = y.dropna()\n",
    "X = X.dropna()\n",
    "\n",
    "ols_kch = sm.OLS(y, sm.add_constant(X)).fit()\n",
    "ols_kch.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot showing top 3 features \n",
    "\n",
    "x_axis = ['True ft²', 'Construction Grade', 'Bedrooms']\n",
    "y_axis = [65000, 64000, 3300]\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25,16))\n",
    "sns.set(rc={'axes.facecolor':'white', 'figure.facecolor':'white'})\n",
    "sns.barplot( x = x_axis, y = y_axis, );\n",
    "\n",
    "plt.title('Positive Correlation on Price ', fontsize=30)\n",
    "plt.xlabel('Main Features', fontsize=40)\n",
    "plt.ylabel('Price increase in Dollars', fontsize=40)\n",
    "plt.xticks(rotation=0, fontsize=25)\n",
    "plt.yticks(fontsize=20)\n",
    "#plt.gcf().axes[0].yaxis.get_major_formatter().set_scientific(False)\n",
    "ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,}'))\n",
    "ax.annotate('710 ft²',xy=(190, 500), xycoords='axes pixels', fontsize=25)\n",
    "ax.annotate('1 Quality Grade',xy=(620, 500), xycoords='axes pixels', fontsize=25)\n",
    "ax.annotate('1 Bedroom',xy=(1120, 50), xycoords='axes pixels', fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot showing the price range of lots in the range of possibilities to allow for multi-family homes to be developed,\n",
    "# houses ≥ 40,000 ft², that are located in the same zip codes as our list of tech companies.\n",
    "\n",
    "zip_lot_size = clean_null.loc[(clean_null['zipcode'].isin([98052,98102,98103,98105,98109,98119,98121,98134,98164]))\n",
    "                              & (clean_null['sqft_lot'] >= 40000)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,7))\n",
    "\n",
    "sns.set(rc={'axes.facecolor':'white', 'figure.facecolor':'lightgreen'})\n",
    "sns.barplot(data=zip_lot_size, x='sqft_lot', y='price');\n",
    "\n",
    "# plt.bar(data=zip_lot_size, x='sqft_living', height='price')\n",
    "plt.title('Houses ≥ 40,000 ft² Near Tech Companies', fontsize=18)\n",
    "plt.xlabel('Area of Lot (ft²)')\n",
    "plt.ylabel('House Price ($)')\n",
    "plt.xticks(rotation=45)\n",
    "# plt.yticks(labels=((zip_lot_size['price'])/100))\n",
    "plt.gcf().axes[0].yaxis.get_major_formatter().set_scientific(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory graph to see how number of bathrooms correlates with house price\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(8, 6))\n",
    "\n",
    "ax.scatter(X['bathrooms'], y)\n",
    "ax.set_title('Home Price Price vs. bath');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of final multiple linear regression model, showing regression line in red vs actual house price variance in blue\n",
    "\n",
    "\n",
    "X_c = sm.add_constant(zip_ohe_columns) #.drop(['price'], axis=1)\n",
    "y = zip_new_columns['price']\n",
    "\n",
    "model_preds = ols_kch.predict(X_c)\n",
    "resids = y - model_preds\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "ax.scatter(model_preds, y)\n",
    "b, a = np.polyfit(model_preds, y, deg=1)\n",
    "ax.plot(model_preds, a + b * model_preds, color=\"red\", lw=2.5, alpha=0.7) # Plot regression line\n",
    "# R2 = ax.scatter([0.711],[0.711], color='black', marker='D', s=65, alpha=0.0 )\n",
    "ax.legend(('Predicted', 'Actual' ), loc=\"upper left\", framealpha=0.5)\n",
    "# ax.add_artist(legend)\n",
    "ax.annotate('R² = 70%', xy=(700, 80), xycoords='axes pixels')\n",
    "ax.set_xlabel('Predicted Home Prices ($)')\n",
    "ax.set_ylabel('Actual Home Prices ($)')\n",
    "plt.suptitle('Actual Vs. Predicted')\n",
    "ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,}'))\n",
    "ax.xaxis.set_major_formatter(StrMethodFormatter('{x:,}'))\n",
    "# plt.gcf().axes[0].xaxis.get_major_formatter().set_scientific(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Our best fit model is better than the baseline model. The reason for this is because the R² result for the first one is 0.450, compared to our best fit model with an R² of 0.704. As well, the Durbin-Watson (1.958, with 2 being the ideal) is more positively correlated in our best fit model than the baseline model (Durbin-Watson 2.024). \n",
    "We found that the three variables with the highest correlation to sale price were True Ft squared, Construction Grade and Bedrooms. \n",
    "\n",
    "If this model were to be put to use, Dwell Development will see an increase in business because they are not going to have to use reasources in areas that they don't need\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "There were three features had the strongest impact on house price: true square feet (ft² living area - ft² basement), construction grade, and the number of bedrooms. Given this information, Dwell Development will have measureable data to optimize sale price and profit from their future multi-family home construction.\n",
    "\n",
    "One limitation to our model was the fairly significant multicolinearity of some of our features. This was seemingly unavoidable due to the inherantly coupled nature of some aspects of houses, i.e., if more bedrooms are added, it is almost always true that more bathrooms would be too, or more floors and living space to accommodate them. We hope to find any possible workarounds to this limitation going forward.\n",
    "\n",
    "Another factor to consider was the age of the data available. The data available to us went up to the year 2015. House prices have fluctuated a lot in the past few years, especially due to the pandemic's effects on the economy. For future analysis, we would like to mine recent and relevant data and explore trends in pricing over time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
